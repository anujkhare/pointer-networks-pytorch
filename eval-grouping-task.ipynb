{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for grouping task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from docreader.evaluation.metrics import bbox_evaluation\n",
    "\n",
    "import line_grouping_helpers as helpers\n",
    "from pointer_net import PointerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_test = np.load('data/lines-gaussian-0.3/lines_data_test.npz')['arr_0']\n",
    "dataset_test = helpers.LineDataset(data_test, random_shuffle=True)\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(n_in=2).cuda(device=DEVICE)\n",
    "model.load_state_dict(torch.load('/opt/weights/ptr-line-grouping-gaussian-0.3-1.02/115_0.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "datum = dataset_test[221]\n",
    "points = datum['sequence']\n",
    "target_pointers = datum['pointers']\n",
    "\n",
    "# Predict\n",
    "n_targets = len(target_pointers)  # NOTE: WE'RE USING THIS FOR LENGTH! NEED EOS TOKEN IDEALLY\n",
    "pred_pointers = predict(points, n_targets)\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Target')\n",
    "plt.yticks(np.arange(13) / 10 + 0.015, np.arange(13) / 10)\n",
    "plt.grid()\n",
    "helpers.plot_points_and_lines(points, target_pointers)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Predictions')\n",
    "helpers.plot_points_and_lines(points, pred_pointers)\n",
    "plt.yticks(np.arange(13) / 10 + 0.015, np.arange(13) / 10)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The overall task has two components:\n",
    "1. \"Grouping\": Can the model correctly group all the words in one text-line together?\n",
    "2. \"Ordering\": Can the model predict the correct order of the words in the text-line?\n",
    "\n",
    "\n",
    "Accordingly the metrics are defined as follows:\n",
    "1. \"Grouping correctness\": consider each line as a \"set\" of words and calculate IoU\n",
    "    1. Post-processing\n",
    "        1. Order does NOT matter\n",
    "        2. Duplicates removed (1, 2, 2, 3 -> 1, 2, 3)\n",
    "    2. Evaluation: calculate by controlling two parameters:\n",
    "        1. IoU of the text-line bounding boxes\n",
    "        2. Edit-distance between the sorted labels (target: {11, 12, 13}, pred: {11, 13} -> edit distance = 1)\n",
    "2. Absolute order correctness (:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _calculate_iou_lists(list1, list2) -> float:\n",
    "    \"\"\"\n",
    "    NOTE:\n",
    "        1. Ignores duplicate elements\n",
    "        2. Order insensitive\n",
    "    \"\"\"\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "@np.vectorize\n",
    "def calculate_iou_lists(list1, list2) -> float:\n",
    "    return _calculate_iou_lists(list1, list2)\n",
    "\n",
    "\n",
    "LineMetrics = collections.namedtuple('LineMetrics', ['tp', 'fn', 'fp', 'n_targets', 'n_preds',])\n",
    "\n",
    "\n",
    "def get_line_grouping_metrics(points, target_pointers, pred_pointers, iou_thresh=.75):\n",
    "    # Split into lines\n",
    "    _, target_line_pointers = helpers.get_lines_from_pointers(points, target_pointers, return_labels=True)\n",
    "    _, pred_line_pointers = helpers.get_lines_from_pointers(points, pred_pointers, return_labels=True)\n",
    "\n",
    "    pred_line_pointers = np.array(pred_line_pointers)\n",
    "    target_line_pointers = np.array(target_line_pointers)\n",
    "    n_targets = len(target_line_pointers)\n",
    "    n_preds = len(pred_line_pointers)\n",
    "    \n",
    "    if len(target_line_pointers.shape) != 1 or len(pred_line_pointers.shape) != 1:\n",
    "        return LineMetrics(tp=0, fp=0, fn=0, n_targets=0, n_preds=0)\n",
    "    \n",
    "    if n_preds == 1 and n_targets == 1:\n",
    "        target = list(target_line_pointers[0])\n",
    "        pred = list(pred_line_pointers[0])\n",
    "        ious = np.array([[_calculate_iou_lists(target, pred)]])\n",
    "    elif n_preds == 1:\n",
    "        pred = list(pred_line_pointers[0])\n",
    "        ious = np.array([[_calculate_iou_lists(target, pred) for target in target_line_pointers]])\n",
    "    elif n_targets == 1:\n",
    "        target = list(target_line_pointers[0])\n",
    "        ious = np.array([[_calculate_iou_lists(target, pred) for pred in pred_line_pointers]]).T\n",
    "    else:\n",
    "        # Broadcast\n",
    "        pred_line_pointers = np.array(pred_line_pointers)[:, np.newaxis]  # n_preds * 1\n",
    "        target_line_pointers = np.array(target_line_pointers)[np.newaxis, :]  # 1 * n_targets\n",
    "\n",
    "        # Calculate n_preds * n_targets\n",
    "        preds = np.repeat(pred_line_pointers, n_targets, axis=1)\n",
    "        targets = np.repeat(target_line_pointers, n_preds, axis=0)\n",
    "\n",
    "        assert np.all(preds.shape == np.array([n_preds, n_targets]))\n",
    "        assert np.all(targets.shape == np.array([n_preds, n_targets]))\n",
    "\n",
    "        ious = calculate_iou_lists(preds, targets)\n",
    "\n",
    "    assert np.all(ious.shape == np.array([n_preds, n_targets]))\n",
    "\n",
    "    # Match\n",
    "    rows_org, cols_org = np.unravel_index(np.argsort(-ious.ravel()), ious.shape)\n",
    "    idx_th = np.where(ious[rows_org, cols_org] >= iou_thresh)\n",
    "    rows = rows_org[idx_th]\n",
    "    cols = cols_org[idx_th]\n",
    "\n",
    "    # While obtaining the unique rows and columns, make sure that the order is maintained (highest IoU first)\n",
    "    # FIXME: I've used pandas right now just because it was easy, we should do it the numpy way eventually\n",
    "    df_inds = pd.DataFrame([rows, cols]).T\n",
    "    df_inds = df_inds.drop_duplicates(subset=[0], keep='first').drop_duplicates(subset=[1], keep='first')\n",
    "    matched_pred = df_inds[0].tolist()\n",
    "    matched_gt = df_inds[1].tolist()\n",
    "\n",
    "    tp = len(matched_gt)  # Number of textlines found with IoU >= iou_thresh\n",
    "    fn = n_targets - tp  # Misses\n",
    "    fp = n_preds - tp  # Extra predictions\n",
    "    \n",
    "    return LineMetrics(\n",
    "        tp=tp,\n",
    "        fp=fp,\n",
    "        fn=fn,\n",
    "        n_targets=n_targets,\n",
    "        n_preds=n_preds,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gts_preds(dataset, n_iters):\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_points = []\n",
    "    for ix in tqdm(range(n_iters)):\n",
    "        # Get the data\n",
    "        datum = dataset[ix]\n",
    "        points = datum['sequence']\n",
    "        target_pointers = datum['pointers']\n",
    "\n",
    "        # Predict\n",
    "        n_targets = len(target_pointers)  # NOTE: WE'RE USING THIS FOR LENGTH! NEED EOS TOKEN IDEALLY\n",
    "        pred_pointers = predict(points, n_targets)\n",
    "    \n",
    "        all_preds.append(pred_pointers)\n",
    "        all_targets.append(target_pointers)\n",
    "        all_points.append(points)\n",
    "    return all_targets, all_preds, all_points\n",
    "\n",
    "def get_textline_accuracy_by_sets(all_points, all_targets, all_preds, iou_thresh=0.75):\n",
    "    assert len(all_targets) == len(all_preds)\n",
    "\n",
    "    tp_total, n_targets_total = 0, 0\n",
    "    for points, target_pointers, pred_pointers in zip(all_points, all_targets, all_preds):\n",
    "        metrics = get_line_grouping_metrics(points, target_pointers=target_pointers, pred_pointers=pred_pointers, iou_thresh=iou_thresh)\n",
    "        tp = metrics.tp\n",
    "        n_targets = metrics.n_targets\n",
    "        assert tp <= n_targets\n",
    "        tp_total += tp\n",
    "        n_targets_total += n_targets\n",
    "\n",
    "    return tp_total/ n_targets_total, (tp_total, n_targets_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_targets, all_preds, all_points = get_all_gts_preds(dataset_test, n_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ious = [0.2, 0.4, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 1]\n",
    "accs = []\n",
    "for iou_thresh in ious:\n",
    "    acc, (tp, n_targets) = get_textline_accuracy_by_sets(all_points, all_targets, all_preds, iou_thresh=iou_thresh)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ious, accs, 'x-')\n",
    "plt.title('Text-line accuracy (as sets) vs IoU')\n",
    "plt.xlabel('IoU')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative results on document data\n",
    "\n",
    "This **will perform poorly** since the training data had y-coordinates discretized to 0.1 intervals which is not the case with the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docschema.semantic import Document\n",
    "import cv2\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doc_data, doc_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = doc_data.Preprocessor(TextLine, crop_h=500, crop_w=500, random_shuffle=False, only_midpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = pathlib.Path('/opt/data/document-datasets/acord/acord-test-files/125-2007-10/125 2007-10 - (17.12)-copy(2).json')\n",
    "path_to_image = path_to_json.with_suffix('.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document.load(str(path_to_json))\n",
    "image = cv2.imread(str(path_to_image))\n",
    "doc.rendered_image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = preprocessor(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points=datum['bboxes']\n",
    "pointers=datum['pointers']\n",
    "image=datum['image']\n",
    "scale=datum['scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "doc_visualize.plot_points_and_lines(points=points, pointers=pointers, image=image, scale=scale, fontsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = torch.from_numpy(points.astype(np.float32)[np.newaxis, ...]).cuda(DEVICE)\n",
    "seq_lens = [sequence.shape[1]]\n",
    "n_outputs = len(pointers)\n",
    "pred_pointer_probs = model(sequence, seq_lens, max_output_len=n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pointers = pred_pointer_probs.argmax(dim=-1).data.cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "doc_visualize.plot_points_and_lines(points=points, pointers=pred_pointers, image=image, scale=scale, fontsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
